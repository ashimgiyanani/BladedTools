# -*- coding: utf-8 -*-
"""
@file: %(file)
@description: This script reads in the Bladed format file *.wnd and post-processes the information
@syntax: 
@inputs:

@outputs:
@example:

See also: readBladed(filename),  OTHER_FUNCTION_NAME2

@Author: %(username), PhD candidate, TU Delft
Wind energy department, TU Delft
email address: ashimgiyanani@yahoo.com
March 2018; Last revision: 06-04-2018
Created on %(date)s
@version: 0.1
"""

# update all older packages in pip, comment after use
# import pip
# from subprocess import call
#
# packages = [dist.project_name for dist in pip.get_installed_distributions()]
# call("pip install --upgrade " + ' '.join(packages), shell=True)
# from IPython import get_ipython
# get_ipython().magic('reset -sf')
########################################################

import sys

import math
import re
import readBladed as rb
import numpy as np
import scipy as sp
from scipy.interpolate import interp1d
from scipy import signal
import matplotlib.pyplot as plt
np.set_printoptions(threshold=np.nan)
import pylab as pyl
import spectrum
from spectrum import tools
# import errors
from spectrum.tools import nextpow2

## To get started first import the DOLfYN ADV advanced programming interface (API):
import dolfyn as df
from dolfyn.tools.psd import psd
from dolfyn.tools.misc import detrend

# Options
NormalizeSpectrum = 0 # normalize the spectrum, yes-1, n0-0
WriteFile = 0 # write to a file
PlotFig = 0 # plot figures , yes-1, no-0
Analyse = 'plane' # post processing for a 'point' / 'plane' or 'domain'
verifyScales = 1  # verify the length scale, yes-1, no-0
Validation = 1  # validation of the spectrum, yes-1, no-0
isolatedEstimation=1 # estimation of length scale and decay in isolation, yes-1, no-0
TaylorMicroscale=1 # estimation of taylor microscle, yes-1, no-0

# load the wind file generated by Bladed
new_path = 'd:\Windwise\PostProcessing'
if new_path not in sys.path:
    sys.path.append(new_path)
filename = "c:\\Users\\ashim.giyanani\\OneDrive - Windwise GmbH\\Windwise\\Bladed\\KaimalWind_125_125_seed888.wnd"
(u, v, w, x, y, z, t, U, delta_x, delta_y, delta_z, Nx, Ny, Nz, Nturb, uvw) = rb.readBladed(filename)

# PLot the uu, vv and ww spectrum
class spec():
    def print(self):
        pass

class grid(spec):
    def print(self):
        pass


km = spec() # create an empty spec record
#if (sum(np.isnan(km.u)) > 0):
#   method = 'linear'
#   idx_u = np.isnan(km.u)
#   km.u[idx_u] = interp1d(t[~idx_u], km.u[~idx_u], kind=method, fill_value='extrapolate')
#plt.figure()
#plt.plot(t,km.u)
#plt.show(block=False)

# Post-processing of the data
km.ref_u = u[8,8,:] # referebce point, hub centre u component
km.ref_v = v[8,8,:] # reference point, v omp
km.ref_w = w[8,8,:] # ref point, w comp

# Measure the spectral densities, coherence and decay factor
km.win = 2**7
km.noverlap = km.win*3/4
km.Nfft = 2**nextpow2(km.ref_u.size)
km.dt = np.nanmean(np.diff(t))
km.Fs = 1/km.dt
km.T = t[-1]
km.t = np.arange(km.dt,km.T,km.dt)
km.N = u.size
km.k = np.fix((km.N-km.noverlap)/(km.win-km.noverlap))
km.df = 1/km.T
km.f = (np.arange(km.t.size)/2)*km.df
km.kw = 2*math.pi*km.f/np.nanmean(u)
km.Spectrum = 'twosided'
km.W = np.fft.fft(np.hamming(km.win))
km.WW = km.W*km.W.conj()
km.KMU = sum(km.WW)*km.k*(1/km.win)*km.Fs

# Statistics of the turbulent field
km.grid = grid()
km.grid.std_u = np.empty(shape=(u.shape[0], u.shape[1])) # initialisation using empty array
km.grid.var_u = km.grid.std_u
km.grid.cov_u = km.grid.std_u
km.grid.R_u = km.grid.std_u
km.grid.xR_u = km.grid.std_u

filew = "c:\\Users\\ashim.giyanani\\OneDrive - Windwise GmbH\\Windwise\\Bladed\\TrialData_Kaimal_125_125_seed888.txt"
for i in np.arange(0,y.size, 1):
    for j in np.arange(0,z.size,1):
        km.grid.std_u[i,j] = np.std(u[i,j,:])
        km.grid.var_u[i,j] = np.var(u[i,j,:])
        km.grid.cov_u[i,j] = np.cov(u[i,j,:])
        km.grid.R_u[i,j] = (np.corrcoef(u[i,j,:], u[8,8,:])[0,1])**2

# Write the std deviations to a file (for Dennis)
if (WriteFile == 1):
#    np.savetxt(filew, z,fmt= "%f" )
    np.savetxt(filew, km.grid.R_u, fmt= "%4.3f")
       


[Y,Z] = np.meshgrid(y,z)
ref_u = u[8,8,:]
km.std_u = np.empty(shape=(u.shape[0], u.shape[1]))
km.var_u = np.empty(shape=(u.shape[0], u.shape[1]))
km.cov_u = np.empty(shape=(u.shape[0], u.shape[1]))
km.R_u = np.empty(shape=(u.shape[0], u.shape[1]))
km.A_u = np.empty(shape=(u.shape[0], u.shape[1]))
km.Sij = np.empty(shape=(u.shape[0], u.shape[1], np.int(km.Nfft/2+1)), dtype=complex)
km.Sii = km.Sij
km.Sjj = km.Sij
km.Cij = np.empty(shape=(u.shape[0], u.shape[1], np.int(km.Nfft/2+1)), dtype=complex)
Theta_ij = km.Sij
km.Coh = np.empty(shape=(u.shape[0], u.shape[1], np.int(km.Nfft/2+1)), dtype=complex)
km.Cij_2 = np.empty(shape=(u.shape[0], u.shape[1], np.int(km.Nfft/2+1)), dtype=complex)
km.CoCoh = km.Cij_2
km.QuadCoh = km.Cij_2
km.Phase = km.Cij_2
km.G = km.Cij_2
km.P = km.Cij_2
km.Q = km.Cij_2
count = 0
for i in range(len(y)):
    for j in range(len(z)):
        count = count + 1 
        km.u = u[i,j,:]
        # General statistics
        km.std_u[i,j] = np.std(km.u)                 # standard deviation
        km.var_u[i,j] = np.var(km.u)                 # variance
        km.cov_u[i,j] = np.cov(km.u)                 # covariance
        km.R_u[i,j] = np.corrcoef(km.u) # cross-correlation coeff
        km.A_u[i,j] = np.correlate(km.u, km.u) # autocorrelation
        # Spectrum
        [km.fii, Sii_temp] = np.asarray(sp.signal.csd(km.u, km.u, km.Fs, window='hamming',  nperseg=km.Nfft, noverlap=km.noverlap, return_onesided=False, scaling='density', detrend=False))
        [km.fjj, Sjj_temp] = np.asarray(sp.signal.csd(ref_u, ref_u, km.Fs, window='hamming',  nperseg=km.Nfft, noverlap=km.noverlap, return_onesided=False, scaling='density', detrend=False))
        [km.fij, Sij_temp] = np.asarray(sp.signal.csd(km.u, ref_u, km.Fs, window='hamming',  nperseg=km.Nfft, noverlap=km.noverlap, return_onesided=False, scaling='density', detrend=False))
        [fij_temp, km.Cij[i,j,:]] = sp.signal.coherence(km.u, ref_u, km.Fs, window='hamming',  nperseg=km.Nfft, noverlap=km.noverlap, detrend=False, )
        Theta_ij[i,j,:] = np.rad2deg(np.angle(km.Sij[i,j,:]))

        # Normalizing the spectrum
        if (NormalizeSpectrum == 1):
          Sii_temp = Sii_temp/KMU
          Sjj_temp = Sjj_temp/KMU
          Sij_temp = Sij_temp/KMU

        # Transfoer the power in the spectrum to one side
        if bool(re.match(r'twosided',km.Spectrum)):
            Sii_temp = Sii_temp[0:(km.Nfft//2+1)]
            Sjj_temp = Sjj_temp[0:(km.Nfft//2+1)]
            Sij_temp = Sij_temp[0:(km.Nfft//2+1)]
            Sii_temp[1:] = 2*Sii_temp[1:] # doubling the spectrum power except the max center value
            Sjj_temp[1:] = 2*Sjj_temp[1:]
            Sij_temp[1:] = 2*Sij_temp[1:]
            km.fij = km.fij[0:(km.Nfft//2+1)]
            km.fii = km.fii[0:(km.Nfft//2+1)]
            km.fjj = km.fjj[0:(km.Nfft//2+1)]
                          
#        # Calculating the co-coherence and the quad-coherence
        km.CoCoh[i,j,:] = (km.Sij[i,j,:]).real/np.sqrt(km.Sii[i,j,:]*km.Sjj[i,j,:]) # root co-coherence
        km.QuadCoh[i,j,:] = np.divide( (km.Sij[i,j,:]).imag, (np.sqrt(km.Sii[i,j,:]*km.Sjj[i,j,:])) )# root quad-coherence
        km.Coh[i,j,:] = km.CoCoh[i,j,:]**2 + km.QuadCoh[i,j,:]**2                   # Coherence
        km.Phase[i,j,:] = np.arctan( np.divide( km.Sij[i,j,:].imag , km.Sij[i,j,:].real ) )# phase shift
        km.Cij_2[i,j,:] = np.divide( np.abs(km.Sij[i,j,:]**2) , (km.Sii[i,j,:]*km.Sjj[i,j,:]) )# coherence as well
        km.G[i,j,:] = np.sqrt(np.divide(km.Sii[i,j,:] , km.Sjj[i,j,:]))      # complex transfer function
        km.P[i,j,:] = km.Cij_2[i,j,:]*np.cos((km.Phase[i,j,:]))*np.sqrt(km.Sii[i,j,:]*km.Sjj[i,j,:])
        km.Q[i,j,:] = km.Cij_2[i,j,:]*np.sin((km.Phase[i,j,:]))*np.sqrt(km.Sii[i,j,:]*km.Sjj[i,j,:])

#        # Caluclate the coherence according to Dolfyn package
#        C_ab = cohere(ref_u, km.u, km.Nfft, window=km.win, debias=True, noise=(0, 0))
           
if (PlotFig == 1):
   plt.figure()
   plt.semilogx(km.fij, Sii_temp)
   plt.show(block=False)










